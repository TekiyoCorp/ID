import Vision
import UIKit
import CoreImage

struct PhotoValidationResult {
    let isValid: Bool
    let errors: [PhotoValidationError]
    
    var errorMessage: String? {
        guard !errors.isEmpty else { return nil }
        return errors.map { $0.localizedDescription }.joined(separator: "\n")
    }
}

enum PhotoValidationError: Error {
    case noFaceDetected
    case multipleFacesDetected
    case faceNotFrontFacing
    case faceTooSmall
    case poorLighting
    case eyesClosed
    case wearingSunglasses
    case faceNotCentered
    case blurryImage
    
    var localizedDescription: String {
        switch self {
        case .noFaceDetected:
            return "‚ùå Aucun visage d√©tect√©"
        case .multipleFacesDetected:
            return "‚ùå Plusieurs visages d√©tect√©s. Une seule personne doit appara√Ætre"
        case .faceNotFrontFacing:
            return "‚ùå Regardez droit devant la cam√©ra"
        case .faceTooSmall:
            return "‚ùå Visage trop petit. Rapprochez-vous"
        case .poorLighting:
            return "‚ùå Luminosit√© insuffisante. Trouvez un meilleur √©clairage"
        case .eyesClosed:
            return "‚ùå Ouvrez les yeux"
        case .wearingSunglasses:
            return "‚ùå Retirez vos lunettes de soleil"
        case .faceNotCentered:
            return "‚ùå Centrez votre visage dans le cercle"
        case .blurryImage:
            return "‚ùå Image floue. Tenez l'appareil stable"
        }
    }
}

@MainActor
final class PhotoValidator {
    
    static let shared = PhotoValidator()
    
    private init() {}
    
    /// Valide une photo pour un usage administratif
    func validatePhoto(_ image: UIImage) async -> PhotoValidationResult {
        print("üîç PhotoValidator: Starting validation...")
        
        guard let cgImage = image.cgImage else {
            print("‚ùå PhotoValidator: Cannot get CGImage")
            return PhotoValidationResult(isValid: false, errors: [.noFaceDetected])
        }
        
        var errors: [PhotoValidationError] = []
        
        // 1. V√©rifier la luminosit√©
        if !checkBrightness(image: cgImage) {
            errors.append(.poorLighting)
        }
        
        // 2. V√©rifier le flou - D√âSACTIV√â (trop strict)
        // if !checkSharpness(image: cgImage) {
        //     errors.append(.blurryImage)
        // }
        
        // 3. D√©tecter et valider le visage
        let faceErrors = await validateFace(cgImage: cgImage)
        errors.append(contentsOf: faceErrors)
        
        let isValid = errors.isEmpty
        print(isValid ? "‚úÖ PhotoValidator: Photo is valid" : "‚ùå PhotoValidator: Photo is invalid - \(errors.count) errors")
        
        return PhotoValidationResult(isValid: isValid, errors: errors)
    }
    
    // MARK: - Face Validation
    
    private func validateFace(cgImage: CGImage) async -> [PhotoValidationError] {
        return await withCheckedContinuation { continuation in
            var errors: [PhotoValidationError] = []
            
            let request = VNDetectFaceRectanglesRequest { request, error in
                if let error = error {
                    print("‚ùå PhotoValidator: Face detection error: \(error.localizedDescription)")
                    errors.append(.noFaceDetected)
                    continuation.resume(returning: errors)
                    return
                }
                
                guard let observations = request.results as? [VNFaceObservation] else {
                    print("‚ùå PhotoValidator: No face observations")
                    errors.append(.noFaceDetected)
                    continuation.resume(returning: errors)
                    return
                }
                
                // V√©rifier le nombre de visages
                print("üîç PhotoValidator: Detected \(observations.count) face(s)")
                
                if observations.isEmpty {
                    errors.append(.noFaceDetected)
                    continuation.resume(returning: errors)
                    return
                }
                
                if observations.count > 1 {
                    errors.append(.multipleFacesDetected)
                    continuation.resume(returning: errors)
                    return
                }
                
                // Analyser le visage unique
                let face = observations[0]
                errors.append(contentsOf: self.analyzeFace(face, imageSize: CGSize(width: cgImage.width, height: cgImage.height)))
                
                continuation.resume(returning: errors)
            }
            
            // Activer la d√©tection de landmarks pour plus de d√©tails
            request.revision = VNDetectFaceRectanglesRequestRevision3
            
            let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])
            
            do {
                try handler.perform([request])
            } catch {
                print("‚ùå PhotoValidator: Failed to perform face detection: \(error.localizedDescription)")
                errors.append(.noFaceDetected)
                continuation.resume(returning: errors)
            }
        }
    }
    
    private func analyzeFace(_ face: VNFaceObservation, imageSize: CGSize) -> [PhotoValidationError] {
        var errors: [PhotoValidationError] = []
        
        // 1. V√©rifier la taille du visage (assoupli: 8% minimum au lieu de 15%)
        let faceArea = face.boundingBox.width * face.boundingBox.height
        print("üîç PhotoValidator: Face area: \(String(format: "%.1f", faceArea * 100))%")
        
        if faceArea < 0.08 { // 8% minimum (plus permissif)
            errors.append(.faceTooSmall)
        }
        
        // 2. V√©rifier le centrage (assoupli: plus de marge)
        let faceCenterX = face.boundingBox.midX
        let faceCenterY = face.boundingBox.midY
        print("üîç PhotoValidator: Face center: x=\(String(format: "%.2f", faceCenterX)), y=\(String(format: "%.2f", faceCenterY))")
        
        // Le visage doit √™tre dans une zone plus large (20%-80% au lieu de 30%-70%)
        if faceCenterX < 0.2 || faceCenterX > 0.8 || faceCenterY < 0.2 || faceCenterY > 0.8 {
            errors.append(.faceNotCentered)
        }
        
        // 3. V√©rifier l'angle (yaw = rotation horizontale) - assoupli √† 30¬∞
        if let yaw = face.yaw?.doubleValue {
            print("üîç PhotoValidator: Face yaw: \(String(format: "%.2f", yaw)) rad (\(String(format: "%.1f", yaw * 180 / .pi))¬∞)")
            // Yaw assoupli √† 30¬∞ (0.52 radians au lieu de 0.26)
            if abs(yaw) > 0.52 {
                errors.append(.faceNotFrontFacing)
            }
        }
        
        // 4. V√©rifier pitch (inclinaison t√™te) - assoupli √† 35¬∞
        if let pitch = face.pitch?.doubleValue {
            print("üîç PhotoValidator: Face pitch: \(String(format: "%.2f", pitch)) rad (\(String(format: "%.1f", pitch * 180 / .pi))¬∞)")
            if abs(pitch) > 0.61 { // ~35 degr√©s (au lieu de 20)
                errors.append(.faceNotFrontFacing)
            }
        }
        
        return errors
    }
    
    // MARK: - Brightness Check
    
    private func checkBrightness(image: CGImage) -> Bool {
        let ciImage = CIImage(cgImage: image)
        
        let extentVector = CIVector(x: ciImage.extent.origin.x,
                                     y: ciImage.extent.origin.y,
                                     z: ciImage.extent.size.width,
                                     w: ciImage.extent.size.height)
        
        guard let filter = CIFilter(name: "CIAreaAverage",
                                     parameters: [kCIInputImageKey: ciImage,
                                                 kCIInputExtentKey: extentVector]) else {
            return true // Si on ne peut pas v√©rifier, on consid√®re OK
        }
        
        guard let outputImage = filter.outputImage else { return true }
        
        var bitmap = [UInt8](repeating: 0, count: 4)
        let context = CIContext(options: [.workingColorSpace: kCFNull!])
        context.render(outputImage,
                      toBitmap: &bitmap,
                      rowBytes: 4,
                      bounds: CGRect(x: 0, y: 0, width: 1, height: 1),
                      format: .RGBA8,
                      colorSpace: nil)
        
        // Calculer la luminosit√© moyenne (0-255)
        let brightness = (Int(bitmap[0]) + Int(bitmap[1]) + Int(bitmap[2])) / 3
        print("üîç PhotoValidator: Brightness: \(brightness)/255")
        
        // Luminosit√© minimale assouplie : 40/255 (au lieu de 60)
        return brightness >= 40
    }
    
    // MARK: - Sharpness Check (Laplacian variance)
    
    private func checkSharpness(image: CGImage) -> Bool {
        guard let ciImage = CIImage(image: UIImage(cgImage: image)) else { return true }
        
        // Convertir en niveaux de gris
        guard let grayFilter = CIFilter(name: "CIPhotoEffectMono") else { return true }
        grayFilter.setValue(ciImage, forKey: kCIInputImageKey)
        guard let grayImage = grayFilter.outputImage else { return true }
        
        // Appliquer un filtre de d√©tection de contours
        guard let edgeFilter = CIFilter(name: "CIEdges") else { return true }
        edgeFilter.setValue(grayImage, forKey: kCIInputImageKey)
        edgeFilter.setValue(1.0, forKey: kCIInputIntensityKey)
        guard let edgeImage = edgeFilter.outputImage else { return true }
        
        // Calculer la variance (mesure du flou)
        let extentVector = CIVector(x: edgeImage.extent.origin.x,
                                     y: edgeImage.extent.origin.y,
                                     z: edgeImage.extent.size.width,
                                     w: edgeImage.extent.size.height)
        
        guard let avgFilter = CIFilter(name: "CIAreaAverage",
                                       parameters: [kCIInputImageKey: edgeImage,
                                                   kCIInputExtentKey: extentVector]) else {
            return true
        }
        
        guard let outputImage = avgFilter.outputImage else { return true }
        
        var bitmap = [UInt8](repeating: 0, count: 4)
        let context = CIContext(options: [.workingColorSpace: kCFNull!])
        context.render(outputImage,
                      toBitmap: &bitmap,
                      rowBytes: 4,
                      bounds: CGRect(x: 0, y: 0, width: 1, height: 1),
                      format: .RGBA8,
                      colorSpace: nil)
        
        let sharpness = Int(bitmap[0])
        print("üîç PhotoValidator: Sharpness: \(sharpness)/255")
        
        // Seuil de nettet√© assoupli : 8/255 minimum (au lieu de 15)
        return sharpness >= 8
    }
}

